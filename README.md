# 📊 Kaushik Dwivedi's Portfolio

## 👋 Introduction

Hi there! I'm **Kaushik Dwivedi**, a Data Analyst with over 3 years of experience in automating data workflows, building robust ETL pipelines, and transforming data into actionable insights. Welcome to my GitHub portfolio—check out my Python, SQL, and data engineering projects below.

---

## 🙋‍♂️ About Me

- 💼 Role: Data Analyst (Data Engineering Focus)  
- 📍 Location: Mumbai, India  
- 🌱 Currently exploring: Airflow orchestration, and modern ELT patterns  
- ⚡ Fun Fact: I love automating data tasks and exploring cloud-native tech!

---

## 📁 Portfolio Projects

### 🐍 Python Projects

- **Repository:** [Python Notebooks](https://github.com/goldi90/Data/tree/master/Python%20Notebook)  
- **Description:**  
  My collection of Python notebooks, focusing on exploratory data analysis, data cleaning, and statistical modeling. Built on Kaggle and Google Colab, and soon including ML models serialized with `joblib` and `pickle`.  
- **Skills Applied:**  
  - Data Cleaning & Preprocessing  
  - Exploratory Data Analysis (EDA)  
  - Visualization & Statistical Analysis  
- **Tools:** Python, Pandas, Matplotlib, Jupyter

---

### 🗄️ Advanced SQL Analytics

- **Repository:** [Sql--Advance-analytics](https://github.com/goldi90/Sql--Advance-analytics)  
- **Description:**  
  A comprehensive set of advanced SQL queries for analytics and business insights. This project covers everything from basic aggregate stats (MIN, MAX, AVG, MEDIAN) to advanced techniques like percentiles, correlation, linear regression, window functions, and pivoting—enabling raw tables to become actionable datasets.  
- **Skills Applied:**  
  - Descriptive & Inferential Statistics in SQL  
  - Window Functions & Aggregation  
  - Correlation & Regression Analysis  
  - Complex Data Transformation  
- **Tools:** SQL Server / T‑SQL

---

### ⚙️ ELT Pipeline: Airflow + dbt + PostgreSQL

- **Repository:** [DE_usingWetheStackAPI](https://github.com/goldi90/DE_usingWetheStackAPI)  
- **Description:**  
  This project demonstrates a full ELT (Extract → Load → Transform) pipeline using Airflow, dbt, PostgreSQL, and Docker. It extracts data from an external API, loads it into PostgreSQL, transforms it via dbt models, and orchestrates everything through Airflow—containerized for easy deployment.  
- **Tech Stack:**  
  - Apache Airflow (workflow orchestration)  
  - dbt (SQL-based modeling, testing, and docs)  
  - PostgreSQL  
  - Docker & Docker Compose  
  - Python + Pandas  
- **Highlights:**  
  - Modular ELT pipeline with dbt documentation  
  - Airflow UI for monitoring workflows  
  - Automated data quality tests (dbt)

---

## 📝 Resume

You can view or download my full resume [here (PDF)](https://github.com/kaushik-dwivedi/kaushik-dwivedi/blob/main/Kaushik_dwivedi_CV.pdf).

---

## 🛠️ Languages & Tools

- Python, Pandas, Jupyter  
- SQL / T‑SQL  
- Apache Airflow, dbt, PostgreSQL  
- Docker, Git

---

## 📞 Contact Me

- 📱 Phone: +91 90828 00180  
- 📧 Email: [kaushikdwivedi22@gmail.com](mailto:kaushikdwivedi22@gmail.com)  
- 💼 LinkedIn: [Kaushik Dwivedi](https://www.linkedin.com/in/kaushikdwivedi/)  
- 💻 GitHub: [goldi90](https://github.com/goldi90)

---

🚀 I’m actively seeking roles in **Data Engineering**, where I can build scalable pipelines, automate data workflows, and deliver clean, production-ready datasets. Let’s connect!
